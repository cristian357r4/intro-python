{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBpc0kcLFjZD"
      },
      "source": [
        "# Nubes de palabras\n",
        "\n",
        "Este ejercicio es una adaptación del tutorial disponible en Kaggle [aquí](https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGTzn9ReJdDB"
      },
      "source": [
        "### Cargamos los módulos a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKXw9ZtNJg_w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import re,string,unicodedata\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5XpamBgFrXQ"
      },
      "source": [
        "### Accediendo datos en Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQO_tj2pFi1A",
        "outputId": "2f623d61-d0c2-44a4-a7b3-a96e9e87ae71"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkustmSaGC-J",
        "outputId": "4fa76dab-db27-4b61-e1ee-377248dbdb76"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_WJKHU1GrMp",
        "outputId": "d0b691ca-c630-4192-eaaa-bae55bf75f55"
      },
      "outputs": [],
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcDWzDNQGxLY",
        "outputId": "0eb2a5d7-0a99-4f83-fcf1-652540022e84"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCxVKGzlI9j4",
        "outputId": "9c2d3a6a-41f2-4e18-b331-e0b8d1ea0cbc"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv -O imdb.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI1XPARsI2ex"
      },
      "outputs": [],
      "source": [
        "# Path of the file to read\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/imdb.csv\"\n",
        "\n",
        "# Read the file into a variable fifa_data\n",
        "data = pd.read_csv(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GFv8AnumJnEZ",
        "outputId": "22e67476-a9f4-451c-fcb6-06757d0ca353"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "efR0fU8wL4VI",
        "outputId": "9b12caeb-c378-4ef8-a309-5ca08de4f88b"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEo-BXDkMAE_",
        "outputId": "7bba17c3-34b2-4c8f-8db4-6ca2fef6de8e"
      },
      "outputs": [],
      "source": [
        "data[\"sentiment\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgOYzMEsOhBX"
      },
      "source": [
        "### Creamos las nubes de palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "L7H5LvQ0KPlK",
        "outputId": "edd3a408-61f8-4cb3-919c-830f1ae97120"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud,STOPWORDS\n",
        "\n",
        "plt.figure(figsize=(40,25))\n",
        "\n",
        "# positivos\n",
        "subset = data[data.sentiment==\"positive\"]\n",
        "text = subset.review.values\n",
        "cloud_positivos = WordCloud(\n",
        "                          stopwords=STOPWORDS,\n",
        "                          background_color='black',\n",
        "                          collocations=False,\n",
        "                          width=2500,\n",
        "                          height=1800\n",
        "                         ).generate(\" \".join(text))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis('off')\n",
        "plt.title(\"Comentarios positivos\",fontsize=40)\n",
        "plt.imshow(cloud_positivos)\n",
        "\n",
        "# negativos\n",
        "subset = data[data.sentiment==\"negative\"]\n",
        "text = subset.review.values\n",
        "cloud_positivos = WordCloud(\n",
        "                          stopwords=STOPWORDS,\n",
        "                          background_color='black',\n",
        "                          collocations=False,\n",
        "                          width=2500,\n",
        "                          height=1800\n",
        "                         ).generate(\" \".join(text))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis('off')\n",
        "plt.title(\"Comentarios negativos\",fontsize=40)\n",
        "plt.imshow(cloud_positivos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6AFfjQZNGmy"
      },
      "source": [
        "### Preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCEvgZ9XNMZQ"
      },
      "source": [
        "#### Palabras sin valor (stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRCU4VNqNSUp",
        "outputId": "445e9ff0-16df-4233-cc23-9886f0be5a4d"
      },
      "outputs": [],
      "source": [
        "#Descargamos\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Separación en palabras (Tokenization)\n",
        "tokenizer=ToktokTokenizer()\n",
        "\n",
        "#stopwords en inglés\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkAwqA8tOFC4"
      },
      "source": [
        "### Quitamos etiquetas HTML y texto innecesario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_giUStNOO-f",
        "outputId": "ea0bdd84-3593-44c8-a0c5-0e029bb82d67"
      },
      "outputs": [],
      "source": [
        "#Removemos etiquetas html\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removemos corchetes\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "#Removemos caracteres especiales\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text\n",
        "\n",
        "#Sustituimos múltiples espacios por espacio sencillo\n",
        "def remove_extra_spaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
        "\n",
        "#Convertimos a minúsculas\n",
        "def convert_lowercase(text):\n",
        "  return text.lower()\n",
        "\n",
        "#Removemos texto innecesario\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "    text = convert_lowercase(text)\n",
        "    return text\n",
        "\n",
        "#Apply function on review column\n",
        "data['review']=data['review'].apply(denoise_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYgySAZHS7ZR"
      },
      "source": [
        "### Convertir palabras a su raíz (Text Stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08Bsd1hKTAuY"
      },
      "outputs": [],
      "source": [
        "#Pasando el texto a su raíz\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "#Aplicamos la función en la columna review\n",
        "data['review']=data['review'].apply(simple_stemmer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDyPqmroTqgY"
      },
      "source": [
        "### Quitando las palabras que no aportan valor (stopwords)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMrkaTd8TwlV",
        "outputId": "8a411e33-7689-4053-a828-636f0f6c8400"
      },
      "outputs": [],
      "source": [
        "#seleccionamos las palabras en inglés\n",
        "stop=set(stopwords.words('english'))\n",
        "print(stop)\n",
        "\n",
        "#removemos las stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    return filtered_text\n",
        "\n",
        "#Aplicamos la función en la columna review\n",
        "data['review']=data['review'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtt2MbDAVxOh"
      },
      "source": [
        "### Creamos las nubes de palabras de nuevo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Lw9n5GkWV0CI",
        "outputId": "5b723341-08ad-43cf-ee5f-d153f3083bc7"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud,STOPWORDS\n",
        "\n",
        "plt.figure(figsize=(40,25))\n",
        "\n",
        "# positivos\n",
        "subset = data[data.sentiment==\"positive\"]\n",
        "text = subset.review.values\n",
        "cloud_positivos = WordCloud(\n",
        "                          stopwords=STOPWORDS,\n",
        "                          background_color='black',\n",
        "                          collocations=False,\n",
        "                          width=2500,\n",
        "                          height=1800\n",
        "                         ).generate(\" \".join(text))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis('off')\n",
        "plt.title(\"Comentarios positivos\",fontsize=40)\n",
        "plt.imshow(cloud_positivos)\n",
        "\n",
        "# negativos\n",
        "subset = data[data.sentiment==\"negative\"]\n",
        "text = subset.review.values\n",
        "cloud_positivos = WordCloud(\n",
        "                          stopwords=STOPWORDS,\n",
        "                          background_color='black',\n",
        "                          collocations=False,\n",
        "                          width=2500,\n",
        "                          height=1800\n",
        "                         ).generate(\" \".join(text))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis('off')\n",
        "plt.title(\"Comentarios negativos\",fontsize=40)\n",
        "plt.imshow(cloud_positivos)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

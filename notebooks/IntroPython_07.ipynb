{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKWXreTj95Z6"
      },
      "source": [
        "# Complejidad de los datos\n",
        "\n",
        "### Introducción\n",
        "\n",
        "En esta sesión analizaremos el tema de complejidad de los datos y algunas técnicas para tratar los efectos de la misma. Este cuaderno se basa parcialmente en el material del curso de limpieza de datos de Kaggle disponible [aquí](https://www.kaggle.com/learn/data-cleaning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8qKe50s95Z-"
      },
      "source": [
        "### Gestión de valores omitidos\n",
        "Elimine los valores que faltan o rellénelos con un flujo de trabajo automatizado.\n",
        "\n",
        "La limpieza de datos es una parte clave de la ciencia de datos, pero puede ser muy frustrante. ¿Por qué hay campos de texto ilegibles? ¿Qué hacer con los valores que faltan? ¿Por qué las fechas no tienen el formato correcto? ¿Cómo puede solucionar rápidamente la introducción de datos incoherentes? En este tema, aprenderá por qué se ha encontrado con estos problemas y, lo que es más importante, cómo solucionarlos.\n",
        "\n",
        "En este cuaderno, aprenderá a abordar algunos de los problemas más comunes de limpieza de datos para que pueda analizar sus datos más rápidamente. Realizará cinco ejercicios prácticos con datos reales y desordenados y responderá a algunas de las preguntas más frecuentes sobre la limpieza de datos.\n",
        "\n",
        "En este cuaderno, veremos cómo tratar los valores faltantes u omitidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bySSHnJZ95Z-"
      },
      "source": [
        "#### Primer vistazo a los datos\n",
        "\n",
        "Lo primero que tenemos que hacer es cargar las bibliotecas y el conjunto de datos que vamos a utilizar.\n",
        "\n",
        "Para la demostración, utilizaremos un conjunto de datos de eventos ocurridos en partidos de fútbol americano. Debido al tamaño del conjunto de datos, lo descargaremos y posteriormente lo cargaremos a nuestro espacio temporal. [Ir a la página de descarga](https://www.kaggle.com/code/alexisbcook/handling-missing-values/data?select=NFL+Play+by+Play+2009-2017+%28v4%29.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOMBSNG095Z_",
        "outputId": "4d6bd9f6-3029-4cf4-9381-164958c6442c"
      },
      "outputs": [],
      "source": [
        "# módulos que usaremos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# cargamos los datos\n",
        "nfl_data = pd.read_csv(\"NFL Play by Play 2009-2017 (v4).csv\")\n",
        "\n",
        "# fijamos la semilla para reproducibilidad\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEI_X99_95aA"
      },
      "source": [
        "Lo primero que hay que hacer cuando se recibe un nuevo conjunto de datos es echar un vistazo a algunos de ellos. Esto nos permite ver que todo se lee correctamente y nos da una idea de lo que está pasando con los datos. En este caso, vamos a ver si hay valores perdidos u omitidos, que son representados en Python con `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "ILNIu14E95aA",
        "outputId": "8be11832-50fc-400b-94b9-1fa8fec620ab"
      },
      "outputs": [],
      "source": [
        "nfl_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_W6oH2695aB"
      },
      "source": [
        "¿Observamos datos faltantes?\n",
        "\n",
        "¿Cuántos puntos de datos faltantes tenemos?\n",
        "\n",
        "Bien, ahora sabemos que tenemos algunos valores faltantes. Veamos cuántos tenemos en cada columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DrU9z_795aB",
        "outputId": "45b3c008-7475-4724-9ed9-e63a32bc7606"
      },
      "outputs": [],
      "source": [
        "# obtenemos el número de datos faltantes por columna\n",
        "missing_values_count = nfl_data.isnull().sum()\n",
        "\n",
        "# Revisamos el número de datos faltantes en las primeras 10 columnas del conjunto de datos (tiene 102 columnas en total).\n",
        "missing_values_count[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pVqW_Qr95aC"
      },
      "source": [
        "¿Qué opinas de los resultados mostrados? Sería útil saber qué porcentaje de valores faltan en nuestro conjunto de datos para hacernos una idea más precisa de la magnitud del problema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gACtEoRaOguR",
        "outputId": "9b8e94cf-f429-4b54-e169-35ac6bad254e"
      },
      "outputs": [],
      "source": [
        "print(nfl_data.shape)\n",
        "a,b = nfl_data.shape\n",
        "print(a)\n",
        "print(b)\n",
        "print(a*b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5EXLnNs95aC",
        "outputId": "0b005414-9fa0-40f0-e559-9e2cffc6d87e"
      },
      "outputs": [],
      "source": [
        "# ¿Cuántos valores faltantes tenemos en total en el conjunto datos?\n",
        "print(nfl_data.shape)\n",
        "total_cells = np.product(nfl_data.shape)\n",
        "total_missing = missing_values_count.sum()\n",
        "\n",
        "# porcentaje de datos faltante\n",
        "percent_missing = (total_missing/total_cells) * 100\n",
        "print(f'Celdas totales: {total_cells:,}')   # Se agrega :, a la derecha de la variable para dar formato de miles\n",
        "print(f'Celdas con datos faltantes: {total_missing:,}') # Se agrega :, a la derecha de la variable para dar formato de miles\n",
        "print(f'Porcentaje de datos faltantes: {round(percent_missing,2)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWLqWpQ995aC"
      },
      "source": [
        "¿Qué opinas del porcentaje de datos faltantes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGtzGiAz95aD"
      },
      "source": [
        "#### Averiguar por qué faltan datos\n",
        "\n",
        "Este es el punto en el que entramos en la parte de la ciencia de datos que solemos llamar \"intuición de datos\", es decir, \"analizar realmente los datos e intentar averiguar por qué son como son y cómo afectarán a nuestro análisis\". Puede ser una parte frustrante de la ciencia de datos, especialmente si eres nuevo en este campo y no tienes mucha experiencia. Para tratar los valores que faltan, tendrás que usar tu intuición para averiguar por qué falta el valor. Una de las preguntas más importantes que puede hacerse para averiguarlo es la siguiente:\n",
        "\n",
        "**¿Este valor falta porque no se registró o porque no existe?**\n",
        "\n",
        "Si falta un valor porque no existe (como la altura del hijo mayor de alguien que no tiene hijos), no tiene sentido intentar adivinar cuál podría ser. Estos valores probablemente quieras mantenerlos como NaN. Por otro lado, si falta un valor porque no se registró, puede intentar adivinar cuál podría haber sido basándose en los demás valores de esa columna y fila. Esto se llama imputación, ¡y aprenderemos a hacerlo a continuación! :)\n",
        "\n",
        "Veamos un ejemplo. Observando el número de valores faltantes en el marco de datos nfl_data, nos damos cuenta de que la columna \"TimeSecs\" tiene muchos valores faltantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPBHFJTf95aD",
        "outputId": "acb9e667-0977-432f-f05e-25413fa0384a"
      },
      "outputs": [],
      "source": [
        "# Revisamos el número de datos faltantes en las primeras 10 columnas del conjunto de datos (tiene 102 columnas en total).\n",
        "missing_values_count[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR_eAYIh95aD"
      },
      "source": [
        "Revisando la documentación, podemos ver que esta columna tiene información sobre el número de segundos que quedaban en el partido cuando se hizo la jugada. Esto significa que estos valores probablemente faltan porque no se registraron, y no porque no existan. Por lo tanto, tendría sentido que intentáramos adivinar cuáles deberían ser en lugar de dejarlos como `NaN`.\n",
        "\n",
        "Por otra parte, hay otros campos, como \"PenalizedTeam\", en los que también faltan muchos campos. En este caso, sin embargo, el campo falta porque si no hubo penalización no tiene sentido decir qué equipo fue penalizado. Para esta columna, tendría más sentido dejarla vacía o añadir un tercer valor como \"ninguno\" y utilizarlo para reemplazar los `NaN`.\n",
        "\n",
        "Si está realizando un análisis de datos muy cuidadoso, este es el punto en el que miraría cada columna individualmente para averiguar cuál es la mejor estrategia para rellenar los valores que faltan. En el resto de este cuaderno, trataremos algunas técnicas \"rápidas y sucias\" que pueden ayudarle con los valores que faltan, pero que probablemente acabarán eliminando información útil o añadiendo ruido a los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8bNN-dA95aD"
      },
      "source": [
        "#### Eliminar valores faltantes\n",
        "Si tiene prisa o no tiene motivos para averiguar por qué faltan valores, una opción es eliminar las filas o columnas que contengan valores que falten. (Nota: ¡generalmente no se recomienda este enfoque para proyectos importantes! Suele merecer la pena tomarse el tiempo necesario para revisar los datos y examinar una por una todas las columnas con valores faltantes para conocer realmente el conjunto de datos).\n",
        "\n",
        "Si está seguro de que quiere eliminar las filas con valores faltantes, pandas tiene una función muy útil, dropna() para ayudarle a hacerlo. Vamos a probarla en nuestro conjunto de datos de la NFL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "aCC-LbXn95aD",
        "outputId": "3530f173-a45e-4a24-8ac4-282239c38f05"
      },
      "outputs": [],
      "source": [
        "# eliminar todos los renglones que contengan un valor faltante u omitido\n",
        "nfl_data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU52YwaO95aD"
      },
      "source": [
        "¿Qué sucedió? ¡parece que se han eliminado todos nuestros datos! 😱 Esto se debe a que cada fila de nuestro conjunto de datos tenía al menos un valor faltante. Podríamos tener mejor suerte eliminando todas las columnas que tienen al menos un valor faltante en su lugar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "MTSMg6Oh95aE",
        "outputId": "28fde50b-4da4-4707-d2c4-d705437f4281"
      },
      "outputs": [],
      "source": [
        "# Eliminemos ahora todas las columnas en donde exista un valor faltante\n",
        "columns_with_na_dropped = nfl_data.dropna(axis=1) #Al agregar el parámetro axis=1 estamos indicando que el criterio sea revisar columnas. Por defecto se revisan renglones (axis=0)\n",
        "columns_with_na_dropped.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F9Zx2fy95aE",
        "outputId": "78cde983-37d2-4c2d-f1b9-a82c2c3d376d"
      },
      "outputs": [],
      "source": [
        "columns_with_na_dropped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDbH8ctBTFuM",
        "outputId": "d859dd22-6a64-491f-c226-b44e930a566d"
      },
      "outputs": [],
      "source": [
        "#a, b = nfl_data.shape\n",
        "a = nfl_data.shape[0]\n",
        "b = nfl_data.shape[1]\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbmwdhos95aE"
      },
      "source": [
        "Calcular cuanta información hemos perdido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6gO59CL95aE",
        "outputId": "91d408be-1f67-4a10-88c9-d3b030d32ec8"
      },
      "outputs": [],
      "source": [
        "print(f\"Columnas en el conjunto de datos original: {nfl_data.shape[1]}\")\n",
        "print(f\"Columnas restantes tras eliminar datos faltantes: {columns_with_na_dropped.shape[1]}\")\n",
        "print(f\"Total de columnas eliminadas: {nfl_data.shape[1] - columns_with_na_dropped.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoL3EIta95aE"
      },
      "source": [
        "#### Rellenar automáticamente los valores que faltan\n",
        "Otra opción es intentar rellenar los valores que faltan. Para ello, vamos a tomar una pequeña subsección de los datos de la NFL para que se imprima bien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "_BMKzKX_95aF",
        "outputId": "5639d070-ece2-4a87-cb99-4dae3a7cf68b"
      },
      "outputs": [],
      "source": [
        "# obtenemos un pequeño subconjunto del conjunto de datos de la NFL\n",
        "subset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head()\n",
        "subset_nfl_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Jw-Jfa95aF"
      },
      "source": [
        "Podemos utilizar la función fillna() de Panda para que rellene por nosotros los valores que faltan en un marco de datos. Una opción que tenemos es especificar con qué queremos que se sustituyan los valores NaN. Aquí, estoy diciendo que me gustaría reemplazar todos los valores NaN con 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "S2Hbb2AS95aF",
        "outputId": "017d3638-ba64-4579-f108-9800201709db"
      },
      "outputs": [],
      "source": [
        "# remplazar todos los datos NaN con 0\n",
        "subset_nfl_data.fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_D13Epg95aF"
      },
      "source": [
        "Quizás una mejor estrategia sea sustituir los valores que faltan por cualquier valor que le siga directamente en la misma columna. (Esto tiene mucho sentido para conjuntos de datos en los que las observaciones tienen algún tipo de orden lógico)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Eb6YJfNg95aF",
        "outputId": "bed43cc5-1fac-44bc-9e4c-73698bb84008"
      },
      "outputs": [],
      "source": [
        "# reemplazar todos los NaN con el valor que viene directamente después de él en la misma columna\n",
        "# y sustituir todos los NaN restantes por 0\n",
        "subset_nfl_data.fillna(method='bfill', axis=0).fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXpxJVHB95aF"
      },
      "source": [
        "Opciones para el parámetro `method`:\n",
        "\n",
        "**ffill**\n",
        "\n",
        "Rellenar valores propagando la última observación válida a la siguiente válida.\n",
        "\n",
        "**bfill**\n",
        "\n",
        "Rellenar valores utilizando la siguiente observación válida para rellenar el hueco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "2YeFf_XYVjPr",
        "outputId": "93390419-f384-44bf-d11d-82ce3ac3cd5f"
      },
      "outputs": [],
      "source": [
        "# reemplazar todos los NaN con el valor que viene directamente antes de él en la misma columna\n",
        "# y sustituir todos los NaN restantes por 0\n",
        "subset_nfl_data.fillna(method='ffill', axis=0).fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7QsTC8M95aF"
      },
      "source": [
        "### Escalado y Normalización\n",
        "Transformar variables numéricas para que tengan propiedades útiles.\n",
        "\n",
        "#### Cargamos los módulos a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvoJILGl95aF",
        "outputId": "bf9a7e3b-ef35-4dbe-f51a-6a0624eb528b"
      },
      "outputs": [],
      "source": [
        "%pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-apKtOUV95aG"
      },
      "outputs": [],
      "source": [
        "# módulos a utilizar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# para transformación Box-Cox\n",
        "from scipy import stats\n",
        "\n",
        "# para escalado min_max\n",
        "from mlxtend.preprocessing import minmax_scaling\n",
        "\n",
        "# módulos de visualización\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# fijamos la semilla para reproducibilidad\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcTUe-d095aG"
      },
      "source": [
        "#### Escalado frente a normalización: ¿Cuál es la diferencia?\n",
        "\n",
        "Una de las razones por las que es fácil confundirse entre escalado y normalización es porque los términos a veces se utilizan indistintamente y, para hacerlo aún más confuso, ¡son muy similares! En ambos casos, se transforman los valores de las variables numéricas para que los puntos de datos transformados tengan propiedades útiles específicas. La diferencia es que en el escalado, se cambia el rango de los datos, mientras que en la normalización, cambia la forma de la distribución de los datos.\n",
        "\n",
        "Hablemos un poco más en profundidad de cada una de estas opciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_34rZS195aG"
      },
      "source": [
        "#### Escalado\n",
        "\n",
        "Esto significa que está transformando sus datos para que se ajusten a una escala específica, como 0-100 o 0-1. Es conveniente escalar los datos cuando se utilizan métodos basados en medidas de la distancia entre los puntos de datos, como las máquinas de vectores de soporte (SVM) o los vecinos más cercanos (KNN). Con estos algoritmos, un cambio de \"1\" en cualquier característica numérica recibe la misma importancia.\n",
        "\n",
        "Por ejemplo, puede consultar los precios de algunos productos en yenes y en dólares estadounidenses. Un dólar estadounidense vale unos 100 yenes, pero si no escala los precios, métodos como SVM o KNN considerarán que una diferencia de precio de 1 yen es tan importante como una diferencia de 1 dólar estadounidense. Está claro que esto no encaja con nuestras intuiciones del mundo. Con la divisa, puedes convertir entre divisas. Pero, ¿qué ocurre con la altura y el peso? No está del todo claro cuántas libras equivalen a una pulgada (o cuántos kilogramos equivalen a un metro).\n",
        "\n",
        "Al escalar las variables, puedes comparar diferentes variables en igualdad de condiciones. Para ayudarte a entender cómo es el escalado, veamos un ejemplo inventado. (No te preocupes, en el siguiente ejercicio trabajaremos con datos reales)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "SnuPh2SE95aG",
        "outputId": "c11b5f75-211c-4c24-ac8f-a38900a29ad0"
      },
      "outputs": [],
      "source": [
        "# generar 1000 puntos de datos extraídos aleatoriamente de una distribución exponencial\n",
        "original_data = np.random.exponential(size=1000)\n",
        "\n",
        "# mix-max escala los datos entre 0 y 1\n",
        "scaled_data = minmax_scaling(original_data, columns=[0])\n",
        "\n",
        "# graficamos ambos para comparar\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
        "sns.histplot(original_data, ax=ax[0], kde=True, legend=False)\n",
        "ax[0].set_title(\"Datos Originales\")\n",
        "sns.histplot(scaled_data, ax=ax[1], kde=True, legend=False)\n",
        "ax[1].set_title(\"Datos Escalados\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIN8liZR95aG"
      },
      "source": [
        "Observe que la forma de los datos no cambia, pero que en lugar de ir de 0 a 8, ahora van de 0 a 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK7oeRww95aG"
      },
      "source": [
        "#### Normalización\n",
        "El escalado sólo cambia el rango de los datos. La normalización es una transformación más radical. El objetivo de la normalización es cambiar las observaciones para que puedan describirse como una distribución normal.\n",
        "\n",
        "[Distribución normal](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal): También conocida como \"curva de campana\", es una distribución estadística específica en la que aproximadamente el mismo número de observaciones se sitúan por encima y por debajo de la media, la media y la mediana son iguales y hay más observaciones cerca de la media. La distribución normal también se conoce como distribución de Gauss.\n",
        "\n",
        "En general, normalizará sus datos si va a utilizar una técnica de aprendizaje automático o estadística que asuma que sus datos se distribuyen normalmente. Algunos ejemplos son el análisis discriminante lineal (LDA) y el Bayes ingenuo gaussiano. (Consejo profesional: cualquier método con \"gaussiano\" en el nombre probablemente asume la normalidad).\n",
        "\n",
        "El método que estamos utilizando para normalizar aquí se llama Transformación [Box-Cox](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation). Echemos un vistazo rápido a cómo se ve la normalización de algunos datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "nPk0p5VN95aG",
        "outputId": "da48ea57-5b2d-4000-8d4c-d4dbd79f711c"
      },
      "outputs": [],
      "source": [
        "# normalizar los datos exponenciales con boxcox\n",
        "normalized_data = stats.boxcox(original_data)\n",
        "\n",
        "# graficamos ambos para comparar\n",
        "fig, ax=plt.subplots(1, 2, figsize=(15, 3))\n",
        "sns.histplot(original_data, ax=ax[0], kde=True, legend=False)\n",
        "ax[0].set_title(\"Datos Originales\")\n",
        "sns.histplot(normalized_data[0], ax=ax[1], kde=True, legend=False)\n",
        "ax[1].set_title(\"Datos Normalizados\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DXNyKjD95aH"
      },
      "source": [
        "Observe que la forma de nuestros datos ha cambiado. Antes de la normalización tenían casi forma de L. Pero después de la normalización se parecen más al contorno de una campana (de ahí lo de \"curva de campana\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análisis de fechas\n",
        "Ayuda a Python a reconocer fechas compuestas por día, mes y año.\n",
        "\n",
        "#### Cargamos los módulos y conjunto de datos a utilizar\n",
        "Trabajaremos con un conjunto de datos que contiene información sobre los desprendimientos de tierra ocurridos entre 2007 y 2016."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# módulos a utilizar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "\n",
        "# cargamos los datos\n",
        "landslides = pd.read_csv(\"data/landslides.csv\")\n",
        "\n",
        "# fijamos la semilla para reproducibilidad\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comprobar el tipo de datos de nuestra columna de fecha\n",
        "Empezaremos echando un vistazo a las cinco primeras filas de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "landslides.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estaremos trabajando con la columna \"date\". Revisemos que realmente contenga fechas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imprimir los primeros renglones de la columna \"date\"\n",
        "print(landslides['date'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al ver los datos podemos asumir como humanos que son datos de fechas, pero esto no significa que Python reconozca que son fechas. Si revisamos la última línea de la función head() notamos que el tipo de dato (dtype) es \"object\".\n",
        "\n",
        "Si revisamos la documentación de dtype de pandas, veremos que también hay un dtype específico datetime64. Como el dtype de nuestra columna es object y no datetime64, podemos decir que Python no sabe que esta columna contiene fechas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "También podemos ver sólo el dtype de una columna sin imprimir las primeras filas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Podemos revisar el tipo de dato de una columna\n",
        "landslides['date'].dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"O\" es el código de \"objeto\", por lo que podemos ver que estos dos métodos nos dan la misma información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# También podemos revisar los tipos de dato de todas las columnas\n",
        "landslides.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Convertir nuestras columnas de fecha a datetime\n",
        "Ahora que sabemos que nuestra columna de fecha no está siendo reconocida como una fecha, es hora de convertirla para que sea reconocida como una fecha. Esto se llama \"analizar fechas\" (\"parsing dates\" en inglés) porque estamos tomando una cadena e identificando las partes que la componen.\n",
        "\n",
        "Podemos determinar cuál es el formato de nuestras fechas con una guía llamada \"directiva strftime\", de la que puedes encontrar más información [aquí](https://strftime.org/)]. La idea básica es que hay que señalar donde están las diferentes partes de la fecha y qué signos de puntuación hay entre ellas. Hay muchas partes posibles de una fecha, pero las más comunes son %d para el día, %m para el mes, %y para un año de dos dígitos y %Y para un año de cuatro dígitos.\n",
        "\n",
        "Algunos ejemplos:\n",
        "\n",
        "- 1/17/07 tiene el formato \"%m/%d/%y\".\n",
        "- 17-1-2007 tiene el formato \"%d-%m-%Y\".\n",
        "\n",
        "Si volvemos a mirar la cabecera de la columna \"date\" (fecha) en el conjunto de datos de desprendimientos, vemos que tiene el formato \"month/day/two-digit year\" (mes/día/año de dos dígitos), por lo que podemos utilizar la misma sintaxis que en el primer ejemplo para analizar las fechas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# crear una nueva columna, date_parsed, con las fechas analizadas\n",
        "landslides['date_parsed'] = pd.to_datetime(landslides['date'], format=\"%m/%d/%y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# revisamos los primeros datos\n",
        "landslides['date_parsed'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora que nuestras fechas están correctamente analizadas, podemos interactuar con ellas de forma útil.\n",
        "\n",
        "¿Qué pasa si nos encontramos con un error con múltiples formatos de fecha? Mientras estamos especificando el formato de fecha, a veces se encontrará con un error cuando hay múltiples formatos de fecha en una sola columna. Si eso ocurre, puede hacer que pandas intente deducir cuál debería ser el formato de fecha correcto. Puede hacerlo así:\n",
        "\n",
        "`landslides['date_parsed'] = pd.to_datetime(landslides['Date'], infer_datetime_format=True)`\n",
        "\n",
        "¿Por qué no utilizar siempre infer_datetime_format = True? Hay dos grandes razones para no hacer que pandas adivine siempre el formato de hora. La primera es que pandas no siempre será capaz de averiguar el formato de fecha correcto, especialmente si alguien se ha puesto creativo con la entrada de datos. La segunda es que es mucho más lento que especificar el formato exacto de las fechas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Seleccionar el día del mes\n",
        "Ahora que tenemos una columna de fechas analizadas, podemos extraer información como el día del mes en que se produjo un desprendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# obtener eñ día del mes de la columna date_parsed\n",
        "day_of_month_landslides = landslides['date_parsed'].dt.day\n",
        "day_of_month_landslides.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¿Qué sucede si intentamos hacer lo mismo con la columna \"date\" original?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "day_lanslides = landslides['date'].dt.day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Trazar el día del mes para comprobar el análisis sintáctico de la fecha\n",
        "Uno de los mayores peligros al analizar fechas es confundir los meses y los días. La función to_datetime() tiene mensajes de error muy útiles, pero no está de más volver a comprobar que los días del mes que hemos extraído tienen sentido.\n",
        "\n",
        "Para ello, vamos a trazar un histograma de los días del mes. Esperamos que tenga valores entre 1 y 31 (Con un asterisco en el 31 porque no todos los meses tienen 31 días) y, puesto que no hay razón para suponer que los desprendimientos son más frecuentes en unos días del mes que en otros, esperamos una distribución relativamente uniforme. Veamos si es así:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remover valores nulos (NaN)\n",
        "day_of_month_landslides = day_of_month_landslides.dropna()\n",
        "\n",
        "# graficamos el día del mes\n",
        "sns.displot(day_of_month_landslides, kde=False, bins=31) #KDE (kernel density estimate) representa los datos mediante una curva de densidad de probabilidad continua en una o varias dimensiones.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
